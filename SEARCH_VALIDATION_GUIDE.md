# ê²€ìƒ‰ ê²°ê³¼ ê²€ì¦ ê°€ì´ë“œ

## ğŸ¯ ëª©í‘œ
ê²€ìƒ‰ì–´ë¡œ ê²€ìƒ‰í•œ ê²°ê³¼ê°€ ì‹¤ì œë¡œ í•´ë‹¹ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ”ì§€ ê²€ì¦

---

## ğŸ“‹ ê²€ì¦ ë°©ë²• (3ê°€ì§€)

### ë°©ë²• 1: ìƒí’ˆëª…ì— ê²€ìƒ‰ì–´ í¬í•¨ ì—¬ë¶€ í™•ì¸ (ê¸°ë³¸)

#### SearchPageì— ë©”ì„œë“œ ì¶”ê°€

**íŒŒì¼:** `src/pages/woongjin_app_search_page.py`

```python
from typing import List

class WoongjinAppSearchPage(BasePage):

    # Locators
    SEARCH_INPUT = (AppiumBy.ID, "search_input")
    SEARCH_BUTTON = (AppiumBy.ID, "search_button")
    SEARCH_RESULT_ITEMS = (AppiumBy.XPATH, "//android.widget.TextView[@resource-id='product_name']")
    # ì‹¤ì œ ì•±ì˜ ìƒí’ˆëª… ìš”ì†Œ locatorë¡œ ë³€ê²½ í•„ìš”

    def get_search_results(self) -> List[str]:
        """ê²€ìƒ‰ ê²°ê³¼ ìƒí’ˆëª… ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        elements = self.find_elements(self.SEARCH_RESULT_ITEMS)
        return [element.text for element in elements]

    def verify_search_results_contain_keyword(self, keyword: str) -> bool:
        """ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ê°€ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸"""
        results = self.get_search_results()

        if not results:
            logger.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False

        keyword_lower = keyword.lower()

        for product_name in results:
            if keyword_lower not in product_name.lower():
                logger.warning(f"í‚¤ì›Œë“œ ë¯¸í¬í•¨ ìƒí’ˆ ë°œê²¬: {product_name}")
                return False

        logger.info(f"âœ… ëª¨ë“  ìƒí’ˆ({len(results)}ê°œ)ì´ '{keyword}' í¬í•¨")
        return True

    def get_results_containing_keyword(self, keyword: str) -> List[str]:
        """í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” ìƒí’ˆë§Œ í•„í„°ë§"""
        results = self.get_search_results()
        keyword_lower = keyword.lower()

        matching = [name for name in results if keyword_lower in name.lower()]

        logger.info(f"ê²€ìƒ‰ ê²°ê³¼: ì „ì²´ {len(results)}ê°œ ì¤‘ {len(matching)}ê°œ ì¼ì¹˜")
        return matching
```

---

### ë°©ë²• 2: ì¼ë¶€ë§Œ í¬í•¨ë˜ë„ë¡ ê²€ì¦ (ì‹¤ìš©ì )

ì‹¤ì œ ì•±ì—ì„œëŠ” ì—°ê´€ ìƒí’ˆë„ ë‚˜ì˜¤ë¯€ë¡œ 100% ì¼ì¹˜ëŠ” ì–´ë ¤ì›€

```python
def verify_search_results_relevance(self, keyword: str, threshold: float = 0.7) -> bool:
    """
    ê²€ìƒ‰ ê²°ê³¼ ì¤‘ ì¼ì • ë¹„ìœ¨ ì´ìƒì´ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸

    Args:
        keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
        threshold: ìµœì†Œ ì¼ì¹˜ ë¹„ìœ¨ (0.7 = 70% ì´ìƒ)

    Returns:
        bool: ê¸°ì¤€ ì¶©ì¡± ì—¬ë¶€
    """
    results = self.get_search_results()

    if not results:
        return False

    matching = self.get_results_containing_keyword(keyword)
    match_rate = len(matching) / len(results)

    logger.info(f"ì¼ì¹˜ìœ¨: {match_rate:.1%} (ê¸°ì¤€: {threshold:.0%})")

    return match_rate >= threshold
```

---

### ë°©ë²• 3: ìƒì„¸ ê²€ì¦ (ìƒí’ˆëª… + ì„¤ëª…)

```python
# Locators ì¶”ê°€
PRODUCT_CARDS = (AppiumBy.XPATH, "//android.view.ViewGroup[@resource-id='product_card']")
PRODUCT_NAME = (AppiumBy.ID, "product_name")
PRODUCT_DESCRIPTION = (AppiumBy.ID, "product_description")

def get_detailed_search_results(self) -> List[dict]:
    """ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ ì •ë³´ ë°˜í™˜"""
    product_cards = self.find_elements(self.PRODUCT_CARDS)
    results = []

    for card in product_cards:
        try:
            name = card.find_element(*self.PRODUCT_NAME).text
            description = card.find_element(*self.PRODUCT_DESCRIPTION).text

            results.append({
                "name": name,
                "description": description
            })
        except Exception as e:
            logger.warning(f"ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    return results

def verify_keyword_in_name_or_description(self, keyword: str) -> bool:
    """ìƒí’ˆëª… ë˜ëŠ” ì„¤ëª…ì— í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸"""
    results = self.get_detailed_search_results()
    keyword_lower = keyword.lower()

    all_match = True
    for product in results:
        name_match = keyword_lower in product["name"].lower()
        desc_match = keyword_lower in product["description"].lower()

        if not (name_match or desc_match):
            logger.warning(f"í‚¤ì›Œë“œ ë¯¸í¬í•¨: {product['name']}")
            all_match = False

    return all_match
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ê¸°ë³¸ ê²€ì¦

**íŒŒì¼:** `src/tests/test_search.py`

```python
import allure
import pytest
from utils.logger import get_logger

logger = get_logger(__name__)


@allure.feature("ê²€ìƒ‰")
@allure.story("ê²€ìƒ‰ ê²°ê³¼ ê²€ì¦")
def test_search_results_contain_keyword(home_page, search_page):
    """ê²€ìƒ‰ ê²°ê³¼ê°€ ê²€ìƒ‰ì–´ë¥¼ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸"""
    keyword = "ë™í™”ì±…"

    with allure.step(f"'{keyword}' ê²€ìƒ‰"):
        home_page.click_search_tab()
        search_page.enter_search_keyword(keyword)
        search_page.click_search_button()

    with allure.step("ê²€ìƒ‰ ê²°ê³¼ í™•ì¸"):
        results = search_page.get_search_results()
        assert len(results) > 0, "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤"
        logger.info(f"ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")

    with allure.step("í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ ê²€ì¦"):
        # ëª¨ë“  ê²°ê³¼ê°€ í‚¤ì›Œë“œ í¬í•¨í•˜ëŠ”ì§€
        assert search_page.verify_search_results_contain_keyword(keyword), \
            f"ì¼ë¶€ ìƒí’ˆì´ '{keyword}'ë¥¼ í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"

    with allure.step("ìŠ¤í¬ë¦°ìƒ· ì €ì¥"):
        search_page.take_screenshot(f"search_{keyword}.png")
```

---

### ì˜ˆì‹œ 2: ì¼ì¹˜ìœ¨ ê¸°ë°˜ ê²€ì¦ (ì‹¤ìš©ì )

```python
@pytest.mark.parametrize("keyword,min_match_rate", [
    ("ì±…", 0.7),        # 70% ì´ìƒ ì¼ì¹˜
    ("ë™í™”", 0.6),      # 60% ì´ìƒ ì¼ì¹˜
    ("ê·¸ë¦¼ì±…", 0.8),    # 80% ì´ìƒ ì¼ì¹˜
])
def test_search_results_relevance(home_page, search_page, keyword, min_match_rate):
    """ê²€ìƒ‰ ê²°ê³¼ ê´€ë ¨ì„± í™•ì¸ (ì¼ì¹˜ìœ¨ ê¸°ë°˜)"""

    with allure.step(f"'{keyword}' ê²€ìƒ‰"):
        home_page.click_search_tab()
        search_page.enter_search_keyword(keyword)
        search_page.click_search_button()

    with allure.step(f"ì¼ì¹˜ìœ¨ {min_match_rate:.0%} ì´ìƒ í™•ì¸"):
        assert search_page.verify_search_results_relevance(keyword, min_match_rate), \
            f"ê²€ìƒ‰ ê²°ê³¼ ì¼ì¹˜ìœ¨ì´ {min_match_rate:.0%} ë¯¸ë§Œì…ë‹ˆë‹¤"
```

---

### ì˜ˆì‹œ 3: ê°œë³„ ìƒí’ˆ ê²€ì¦

```python
def test_search_results_detailed(home_page, search_page):
    """ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ ê²€ì¦"""
    keyword = "ë™í™”ì±…"

    with allure.step(f"'{keyword}' ê²€ìƒ‰"):
        home_page.click_search_tab()
        search_page.enter_search_keyword(keyword)
        search_page.click_search_button()

    with allure.step("ê° ìƒí’ˆ ê²€ì¦"):
        results = search_page.get_search_results()
        keyword_lower = keyword.lower()

        matched_count = 0
        for i, product_name in enumerate(results, 1):
            if keyword_lower in product_name.lower():
                logger.info(f"âœ… [{i}] {product_name}")
                matched_count += 1
            else:
                logger.warning(f"âŒ [{i}] {product_name} (í‚¤ì›Œë“œ ë¯¸í¬í•¨)")

        # ìµœì†Œ 70% ì´ìƒ ì¼ì¹˜í•´ì•¼ í†µê³¼
        match_rate = matched_count / len(results)
        assert match_rate >= 0.7, \
            f"ì¼ì¹˜ìœ¨ {match_rate:.1%} (ê¸°ì¤€: 70% ì´ìƒ)"

        allure.attach(
            f"ì¼ì¹˜: {matched_count}/{len(results)} ({match_rate:.1%})",
            name="ê²€ì¦ ê²°ê³¼",
            attachment_type=allure.attachment_type.TEXT
        )
```

---

## ğŸ” ê³ ê¸‰ ê²€ì¦ ë°©ë²•

### 1. í•œê¸€ ìëª¨ ë¶„ë¦¬ ê²€ì¦ (ì´ˆì„± ê²€ìƒ‰)

```python
def normalize_korean(text: str) -> str:
    """í•œê¸€ ì •ê·œí™” (ìëª¨ ë¶„ë¦¬)"""
    import unicodedata
    return unicodedata.normalize('NFC', text)

def verify_search_with_korean(self, keyword: str) -> bool:
    """í•œê¸€ ê²€ìƒ‰ ì‹œ ì •ê·œí™” í›„ ë¹„êµ"""
    results = self.get_search_results()
    keyword_normalized = normalize_korean(keyword.lower())

    for product in results:
        product_normalized = normalize_korean(product.lower())
        if keyword_normalized not in product_normalized:
            return False

    return True
```

---

### 2. ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ì¦ (ì¶”ì²œ)

```python
from difflib import SequenceMatcher

def calculate_similarity(text1: str, text2: str) -> float:
    """ë‘ í…ìŠ¤íŠ¸ ê°„ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)"""
    return SequenceMatcher(None, text1.lower(), text2.lower()).ratio()

def verify_search_by_similarity(self, keyword: str, threshold: float = 0.3) -> bool:
    """
    ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼ ê²€ì¦

    Args:
        keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
        threshold: ìµœì†Œ ìœ ì‚¬ë„ (0.3 = 30% ì´ìƒ)
    """
    results = self.get_search_results()

    for product_name in results:
        similarity = calculate_similarity(keyword, product_name)

        if similarity < threshold:
            logger.warning(f"ìœ ì‚¬ë„ ë‚®ìŒ: {product_name} ({similarity:.1%})")
            return False

    return True
```

---

### 3. ìŠ¤í¬ë¡¤í•˜ë©° ì „ì²´ ê²°ê³¼ ê²€ì¦

```python
def get_all_search_results_with_scroll(self, max_scrolls: int = 5) -> List[str]:
    """ìŠ¤í¬ë¡¤í•˜ë©° ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘"""
    all_results = []
    previous_count = 0

    for i in range(max_scrolls):
        # í˜„ì¬ í™”ë©´ì˜ ê²°ê³¼ ìˆ˜ì§‘
        current_results = self.get_search_results()
        all_results.extend(current_results)

        # ì¤‘ë³µ ì œê±°
        all_results = list(dict.fromkeys(all_results))

        # ë” ì´ìƒ ìƒˆë¡œìš´ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
        if len(all_results) == previous_count:
            logger.info(f"ë” ì´ìƒ ê²°ê³¼ ì—†ìŒ (ìŠ¤í¬ë¡¤ {i}íšŒ)")
            break

        previous_count = len(all_results)

        # ìŠ¤í¬ë¡¤
        self.swipe_up()
        self.wait(1)

    logger.info(f"ì „ì²´ ê²€ìƒ‰ ê²°ê³¼: {len(all_results)}ê°œ")
    return all_results

def test_search_all_results(home_page, search_page):
    """ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ ê²€ì¦ (ìŠ¤í¬ë¡¤ í¬í•¨)"""
    keyword = "ì±…"

    with allure.step(f"'{keyword}' ê²€ìƒ‰"):
        home_page.click_search_tab()
        search_page.enter_search_keyword(keyword)
        search_page.click_search_button()

    with allure.step("ìŠ¤í¬ë¡¤í•˜ë©° ì „ì²´ ê²°ê³¼ ìˆ˜ì§‘"):
        all_results = search_page.get_all_search_results_with_scroll()
        assert len(all_results) >= 10, "ê²€ìƒ‰ ê²°ê³¼ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤"

    with allure.step("í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ ê²€ì¦"):
        matching = [r for r in all_results if keyword in r.lower()]
        match_rate = len(matching) / len(all_results)

        logger.info(f"ì¼ì¹˜: {len(matching)}/{len(all_results)} ({match_rate:.1%})")
        assert match_rate >= 0.5, f"ì¼ì¹˜ìœ¨ì´ 50% ë¯¸ë§Œì…ë‹ˆë‹¤ ({match_rate:.1%})"
```

---

## ğŸ’¡ ì‹¤ë¬´ ê¶Œì¥ ë°©ë²•

### ì¶”ì²œ ì¡°í•©

```python
def test_search_comprehensive(home_page, search_page):
    """ê²€ìƒ‰ ê¸°ëŠ¥ ì¢…í•© í…ŒìŠ¤íŠ¸"""
    keyword = "ë™í™”ì±…"

    with allure.step("1. ê²€ìƒ‰ ì‹¤í–‰"):
        home_page.click_search_tab()
        search_page.enter_search_keyword(keyword)
        search_page.click_search_button()

    with allure.step("2. ê²°ê³¼ ì¡´ì¬ í™•ì¸"):
        results = search_page.get_search_results()
        assert len(results) > 0, "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤"
        logger.info(f"âœ… ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")

    with allure.step("3. ê´€ë ¨ì„± í™•ì¸ (70% ì´ìƒ)"):
        match_rate = search_page.verify_search_results_relevance(keyword, 0.7)
        assert match_rate, "ê²€ìƒ‰ ê²°ê³¼ ê´€ë ¨ì„±ì´ ë‚®ìŠµë‹ˆë‹¤"

    with allure.step("4. ìƒìœ„ 3ê°œ ìƒí’ˆ ê²€ì¦"):
        top_3 = results[:3]
        for i, product in enumerate(top_3, 1):
            logger.info(f"ìƒìœ„ {i}ìœ„: {product}")
            # ìƒìœ„ 3ê°œëŠ” ë°˜ë“œì‹œ í‚¤ì›Œë“œ í¬í•¨í•´ì•¼ í•¨
            assert keyword.lower() in product.lower(), \
                f"ìƒìœ„ {i}ìœ„ ìƒí’ˆì´ '{keyword}'ë¥¼ í¬í•¨í•˜ì§€ ì•ŠìŒ: {product}"

    with allure.step("5. ìŠ¤í¬ë¦°ìƒ· ì €ì¥"):
        search_page.take_screenshot(f"search_{keyword}.png")
```

---

## ğŸ“Š ê²€ì¦ ì „ëµ ë¹„êµ

| ë°©ë²• | ì—„ê²©ë„ | ì‹¤ìš©ì„± | ì¶”ì²œ ì‚¬ìš©ì²˜ |
|------|--------|--------|------------|
| **100% ì¼ì¹˜** | â­â­â­â­â­ | â­ | í…ŒìŠ¤íŠ¸ í™˜ê²½ë§Œ |
| **70% ì¼ì¹˜** | â­â­â­ | â­â­â­â­ | **ì‹¤ë¬´ ì¶”ì²œ** |
| **ìœ ì‚¬ë„ ê¸°ë°˜** | â­â­ | â­â­â­ | ì˜¤íƒ€ í—ˆìš© í•„ìš” ì‹œ |
| **ìƒìœ„ Nê°œë§Œ** | â­â­â­â­ | â­â­â­â­â­ | **í¬íŠ¸í´ë¦¬ì˜¤ ì¶”ì²œ** |

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

### SearchPage êµ¬í˜„
- [ ] `get_search_results()` ë©”ì„œë“œ ì¶”ê°€
- [ ] `verify_search_results_contain_keyword()` ë©”ì„œë“œ ì¶”ê°€
- [ ] `verify_search_results_relevance()` ë©”ì„œë“œ ì¶”ê°€
- [ ] ê²€ìƒ‰ ì…ë ¥/ë²„íŠ¼ Locator ì¶”ê°€

### í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] ê¸°ë³¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
- [ ] ì¼ì¹˜ìœ¨ ê¸°ë°˜ ê²€ì¦ í…ŒìŠ¤íŠ¸
- [ ] ë„¤ê±°í‹°ë¸Œ ì¼€ì´ìŠ¤ (ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)

---

**ì‘ì„±ì¼:** 2025-12-24
**ì¶”ì²œ:** 70% ì¼ì¹˜ìœ¨ + ìƒìœ„ 3ê°œ í•„ìˆ˜ í¬í•¨ ë°©ì‹
